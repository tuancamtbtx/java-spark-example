version: 1.0.0
job:
    sparkConf:
        appName: "test_etl"
        master: "local[*]"
        conf:
            spark.sql.shuffle.partitions: 10
            spark.sql.autoBroadcastJoinThreshold: -1
            hive.metadata.warehouse.dir: "hdfs://localhost:9000/user/hive/warehouse"
    sourceConf:
        format: parquet
        path: "hdfs://localhost:9000/output.parquet"
        schema: "id int, name string"
    transformConf:
        - type: filter
          condition: "col('id') == 1"
        - type: select
          columns: ["id", "name"]
        - type: map
          function: "lambda x: x + 1"
    sinkConf:
        connection: "gcs://test/output.parquet"
        format: parquet